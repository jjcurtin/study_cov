<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Lauren Khoury">
<meta name="author" content="Kendra Wyant">
<meta name="author" content="Markus Brauer">
<meta name="author" content="John J. Curtin">
<meta name="dcterms.date" content="2025-10-23">

<title>Evaluating Methods for Covariate Selection in Experimental Designs</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-e26003cea8cd680ca0c55a263523d882.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-a1ff8711b79ae3724c050874b28d9907.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta name="citation_title" content="Evaluating Methods for Covariate Selection in Experimental Designs">
<meta name="citation_abstract" content="Abstract of paper goes here and can span several lines.
">
<meta name="citation_author" content="Lauren Khoury">
<meta name="citation_author" content="Kendra Wyant">
<meta name="citation_author" content="Markus Brauer">
<meta name="citation_author" content="John J. Curtin">
<meta name="citation_publication_date" content="2025-10-23">
<meta name="citation_cover_date" content="2025-10-23">
<meta name="citation_year" content="2025">
<meta name="citation_online_date" content="2025-10-23">
<meta name="citation_language" content="en">
<meta name="citation_reference" content="citation_title=Choosing covariates in the analysis of clinical trials;,citation_abstract=Much of the literature on clinical trials emphasizes the importance of adjusting the results for any covariates (baseline variables) for which randomization fails to produce nearly exact balance, but the literature is very nearly devoid of recipes for assessing the consequences of such adjustments. Several years ago, Paul Canner presented an approximate expression for the effect of a covariate adjustment, and he considered its use in the selection of covariates. With the aid of Canner’s equation, using both formal analysis and simulation, the impact of covariate adjustment is further explored. Unless tight control over the analysis plans is established in advance, covariate adjustment can lead to seriously misleading inferences. Illustrations from the clinical trials literature are provided.;,citation_author=M. L. Beach;,citation_author=P. Meier;,citation_publication_date=1989-12;,citation_cover_date=1989-12;,citation_year=1989;,citation_issue=4 Suppl;,citation_doi=10.1016/0197-2456(89)90055-x;,citation_issn=0197-2456;,citation_pmid=2605965;,citation_volume=10;,citation_language=en-US;,citation_journal_title=Controlled Clinical Trials;">
<meta name="citation_reference" content="citation_title=Power failure: Why small sample size undermines the reliability of neuroscience;,citation_abstract=A study with low statistical power has a reduced chance of detecting a true effect, but it is less well appreciated that low power also reduces the likelihood that a statistically significant result reflects a true effect. Here, we show that the average statistical power of studies in the neurosciences is very low. The consequences of this include overestimates of effect size and low reproducibility of results. There are also ethical dimensions to this problem, as unreliable research is inefficient and wasteful. Improving reproducibility in neuroscience is a key priority and requires attention to well-established but often ignored methodological principles.;,citation_author=Katherine S. Button;,citation_author=John P. A. Ioannidis;,citation_author=Claire Mokrysz;,citation_author=Brian A. Nosek;,citation_author=Jonathan Flint;,citation_author=Emma S. J. Robinson;,citation_author=Marcus R. Munafò;,citation_publication_date=2013-05;,citation_cover_date=2013-05;,citation_year=2013;,citation_issue=5;,citation_doi=10.1038/nrn3475;,citation_issn=1471-003X;,citation_volume=14;,citation_language=en-US;,citation_journal_title=Nature Reviews Neuroscience;">
<meta name="citation_reference" content="citation_title=Center for high throughput computing;,citation_author=Center for High Throughput Computing;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_doi=10.21231/GNT1-HW21;,citation_publisher=Center for High Throughput Computing;">
<meta name="citation_reference" content="citation_title=A power primer.;,citation_abstract=One possible reason for the continued neglect of statistical power analysis in research in the behavioral sciences is the inaccessibility of or difficulty with the standard material. A convenient, although not comprehensive, presentation of required sample sizes is provided. Effect-size indexes and conventional values for these are given for operationally defined small, medium, and large effects. The sample sizes necessary for .80 power to detect effects at these levels are tabled for 8 standard statistical tests: (1) the difference between independent means, (2) the significance of a product-moment correlation, (3) the difference between independent r s, (4) the sign test, (5) the difference between independent proportions, (6) chi-square tests for goodness of fit and contingency tables, (7) 1-way analysis of variance (ANOVA), and (8) the significance of a multiple or multiple partial correlation.;,citation_author=Jacob Cohen;,citation_publication_date=1992;,citation_cover_date=1992;,citation_year=1992;,citation_issue=1;,citation_volume=112;,citation_journal_title=Psychological Bulletin;">
<meta name="citation_reference" content="citation_title=The statistical power of abnormal-social psychological research: A review;,citation_author=Jacob Cohen;,citation_publication_date=1962;,citation_cover_date=1962;,citation_year=1962;,citation_issue=3;,citation_doi=10.1037/h0045186;,citation_issn=0096-851X;,citation_volume=65;,citation_journal_title=The Journal of Abnormal and Social Psychology;,citation_publisher=American Psychological Association;">
<meta name="citation_reference" content="citation_title=Statistical Power Analysis for the Behavioral Sciences;,citation_abstract=Statistical Power Analysis is a nontechnical guide to power analysis in research planning that provides users of applied statistics with the tools they need for more effective analysis. The Second Edition includes: * a chapter covering power analysis in set correlation and multivariate methods; * a chapter considering effect size, psychometric reliability, and the efficacy of &amp;amp;amp;quot;qualifying&amp;quot; dependent variables and; * expanded power and sample size tables for multiple regression/correlation.;,citation_author=Jacob Cohen;,citation_publication_date=1988-07;,citation_cover_date=1988-07;,citation_year=1988;,citation_isbn=978-0-8058-0283-2;,citation_language=en-US;">
<meta name="citation_reference" content="citation_title=Bias, precision and statistical power of analysis of covariance in the analysis of randomized trials with baseline imbalance: A simulation study;,citation_abstract=Analysis of variance (ANOVA), change-score analysis (CSA) and analysis of covariance (ANCOVA) respond differently to baseline imbalance in randomized controlled trials. However, no empirical studies appear to have quantified the differential bias and precision of estimates derived from these methods of analysis, and their relative statistical power, in relation to combinations of levels of key trial characteristics. This simulation study therefore examined the relative bias, precision and statistical power of these three analyses using simulated trial data.;,citation_author=Bolaji E. Egbewale;,citation_author=Martyn Lewis;,citation_author=Julius Sim;,citation_publication_date=2014-04;,citation_cover_date=2014-04;,citation_year=2014;,citation_issue=1;,citation_doi=10.1186/1471-2288-14-49;,citation_issn=1471-2288;,citation_volume=14;,citation_language=en-US;,citation_journal_title=BMC Medical Research Methodology;">
<meta name="citation_reference" content="citation_title=Covariate adjustment in randomized controlled trials with dichotomous outcomes increases statistical power and reduces sample size requirements;,citation_abstract=Objective Randomized controlled trials (RCTs) with dichotomous outcomes may be analyzed with or without adjustment for baseline characteristics (covariates). We studied type I error, power, and potential reduction in sample size with several covariate adjustment strategies. Study Design and Setting Logistic regression analysis was applied to simulated data sets (n=360) with different treatment effects, covariate effects, outcome incidences, and covariate prevalences. Treatment effects were estimated with or without adjustment for a single dichotomous covariate. Strategies included always adjusting for the covariate (“prespecified”), or only when the covariate was predictive or imbalanced. Results We found that the type I error was generally at the nominal level. The power was highest with prespecified adjustment. The potential reduction in sample size was higher with stronger covariate effects (from 3 to 46%, at 50% outcome incidence and covariate prevalence) and independent of the treatment effect. At lower outcome incidences and/or covariate prevalences, the reduction was lower. Conclusion We conclude that adjustment for a predictive baseline characteristic may lead to a potentially important increase in power of analyses of treatment effect. Adjusted analysis should, hence, be considered more often for RCTs with dichotomous outcomes.;,citation_author=Adrián V Hernández;,citation_author=Ewout W Steyerberg;,citation_author=J. Dik F Habbema;,citation_publication_date=2004-05;,citation_cover_date=2004-05;,citation_year=2004;,citation_issue=5;,citation_doi=10.1016/j.jclinepi.2003.09.014;,citation_issn=0895-4356;,citation_volume=57;,citation_journal_title=Journal of Clinical Epidemiology;">
<meta name="citation_reference" content="citation_title=Randomized Controlled Trials With Time-to-Event Outcomes: How Much Does Prespecified Covariate Adjustment Increase Power?;,citation_abstract=Purpose We evaluated the effects of various strategies of covariate adjustment on type I error, power, and potential reduction in sample size in randomized controlled trials (RCTs) with time-to-event outcomes. Methods We used Cox models in simulated data sets with different treatment effects (hazard ratios [HRs] = 1, 1.4, and 1.7), covariate effects (HRs = 1, 2, and 5), covariate prevalences (10% and 50%), and censoring levels (no, low, and high). Treatment and a single covariate were dichotomous. We examined the sample size that gives the same power as an unadjusted analysis for three strategies: prespecified, significant predictive, and significant imbalance. Results Type I error generally was at the nominal level. The power to detect a true treatment effect was greater with adjusted than unadjusted analyses, especially with prespecified and significant-predictive strategies. Potential reductions in sample size with a covariate HR between 2 and 5 were between 15% and 44% (covariate prevalence 50%) and between 4% and 12% (covariate prevalence 10%). The significant-imbalance strategy yielded small reductions. The reduction was greater with stronger covariate effects, but was independent of treatment effect, sample size, and censoring level. Conclusions Adjustment for one predictive baseline characteristic yields greater power to detect a true treatment effect than unadjusted analysis, without inflation of type I error and with potentially moderate reductions in sample size. Analysis of RCTs with time-to-event outcomes should adjust for predictive covariates.;,citation_author=Adrián V. Hernández;,citation_author=Marinus J. C. Eijkemans;,citation_author=Ewout W. Steyerberg;,citation_publication_date=2006-01;,citation_cover_date=2006-01;,citation_year=2006;,citation_issue=1;,citation_doi=10.1016/j.annepidem.2005.09.007;,citation_issn=1047-2797;,citation_volume=16;,citation_journal_title=Annals of Epidemiology;">
<meta name="citation_reference" content="citation_title=Why most published research findings are false;,citation_abstract=There is increasing concern that most current published research findings are false. The probability that a research claim is true may depend on study power and bias, the number of other studies on the same question, and, importantly, the ratio of true to no relationships among the relationships probed in each scientific field. In this framework, a research finding is less likely to be true when the studies conducted in a field are smaller; when effect sizes are smaller; when there is a greater number and lesser preselection of tested relationships; where there is greater flexibility in designs, definitions, outcomes, and analytical modes; when there is greater financial and other interest and prejudice; and when more teams are involved in a scientific field in chase of statistical significance. Simulations show that for most study designs and settings, it is more likely for a research claim to be false than true. Moreover, for many current scientific fields, claimed research findings may often be simply accurate measures of the prevailing bias. In this essay, I discuss the implications of these problems for the conduct and interpretation of research.;,citation_author=John P. A. Ioannidis;,citation_publication_date=2005-08;,citation_cover_date=2005-08;,citation_year=2005;,citation_issue=8;,citation_doi=10.1371/journal.pmed.0020124;,citation_issn=1549-1676;,citation_pmid=16060722;,citation_volume=2;,citation_language=en-US;,citation_journal_title=PLoS medicine;">
<meta name="citation_reference" content="citation_title=The risks and rewards of covariate adjustment in randomized trials: An assessment of 12 outcomes from 8 studies;,citation_abstract=Background Adjustment for prognostic covariates can lead to increased power in the analysis of randomized trials. However, adjusted analyses are not often performed in practice. Methods We used simulation to examine the impact of covariate adjustment on 12 outcomes from 8 studies across a range of therapeutic areas. We assessed (1) how large an increase in power can be expected in practice; and (2) the impact of adjustment for covariates that are not prognostic. Results Adjustment for known prognostic covariates led to large increases in power for most outcomes. When power was set to 80% based on an unadjusted analysis, covariate adjustment led to a median increase in power to 92.6% across the 12 outcomes (range 80.6 to 99.4%). Power was increased to over 85% for 8 of 12 outcomes, and to over 95% for 5 of 12 outcomes. Conversely, the largest decrease in power from adjustment for covariates that were not prognostic was from 80% to 78.5%. Conclusions Adjustment for known prognostic covariates can lead to substantial increases in power, and should be routinely incorporated into the analysis of randomized trials. The potential benefits of adjusting for a small number of possibly prognostic covariates in trials with moderate or large sample sizes far outweigh the risks of doing so, and so should also be considered.;,citation_author=Brennan C Kahan;,citation_author=Vipul Jairath;,citation_author=Caroline J Doré;,citation_author=Tim P Morris;,citation_publication_date=2014-04;,citation_cover_date=2014-04;,citation_year=2014;,citation_doi=10.1186/1745-6215-15-139;,citation_issn=1745-6215;,citation_pmid=24755011;,citation_volume=15;,citation_journal_title=Trials;">
<meta name="citation_reference" content="citation_title=Subgroup analysis, covariate adjustment and baseline comparisons in clinical trial reporting: Current practiceand problems;,citation_abstract=Clinical trial investigators often record a great deal of baseline data on each patient at randomization. When reporting the trial’s findings such baseline data can be used for (i) subgroup analyses which explore whether there is evidence that the treatment difference depends on certain patient characteristics, (ii) covariate-adjusted analyses which aim to refine the analysis of the overall treatment difference by taking account of the fact that some baseline characteristics are related to outcome and may be unbalanced between treatment groups, and (iii) baseline comparisons which compare the baseline characteristics of patients in each treatment group for any possible (unlucky) differences. This paper examines how these issues are currently tackled in the medical journals, based on a recent survey of 50 trial reports in four major journals. The statistical ramifications are explored, major problems are highlighted and recommendations for future practice are proposed. Key issues include: the overuse and overinterpretation of subgroup analyses; the underuse of appropriate statistical tests for interaction; inconsistencies in the use of covariate-adjustment; the lack of clear guidelines on covariate selection; the overuse of baseline comparisons in some studies; the misuses of significance tests for baseline comparability, and the need for trials to have a predefined statistical analysis plan for all these uses of baseline data. Copyright © 2002 John Wiley &amp;amp;amp; Sons, Ltd.;,citation_author=Stuart J. Pocock;,citation_author=Susan E. Assmann;,citation_author=Laura E. Enos;,citation_author=Linda E. Kasten;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_issue=19;,citation_doi=10.1002/sim.1296;,citation_issn=1097-0258;,citation_volume=21;,citation_language=en-US;,citation_journal_title=Statistics in Medicine;">
<meta name="citation_reference" content="citation_title=Post-hoc selection of covariates in randomized experiments;,citation_abstract=Monte Carlo methods are used to compere a number of adaptive strategies for deciding which of several covariates to incorporate into the analysis of a randomized experiment.Sixteen selection strategies in three categories are considered: 1)select covariates correlated with the response, 2)select covariates with means differing across groups, and 3)select covariates with means differing across groups that are also correlated with the response. The criteria examined are the type I error rate of the test for equality of adjusted group means and the variance of the estimated treatment effect. These strategies can result in either inflated or deflated type I errors, depending on the method and the population parameters. The adaptive methods in the first category some times yieldpoint estimates of the treatment effect more precise than estimators derive dusing either all or none of the covariates.;,citation_author=Mark D. Schelchter;,citation_author=Alan B. Forsythe;,citation_publication_date=1985-01;,citation_cover_date=1985-01;,citation_year=1985;,citation_issue=3;,citation_doi=10.1080/03610928508828942;,citation_issn=0361-0926;,citation_volume=14;,citation_journal_title=Communications in Statistics - Theory and Methods;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant;,citation_abstract=In this article, we accomplish two things. First, we show that despite empirical psychologists’ nominal endorsement of a low rate of false-positive findings ($\leq$ .05), flexibility in data collection, analysis, and reporting dramatically increases actual false-positive rates. In many cases, a researcher is more likely to falsely find evidence that an effect exists than to correctly find evidence that it does not. We present computer simulations and a pair of actual experiments that demonstrate how unacceptably easy it is to accumulate (and report) statistically significant evidence for a false hypothesis. Second, we suggest a simple, low-cost, and straightforwardly effective disclosure-based solution to this problem. The solution involves six concrete requirements for authors and four guidelines for reviewers, all of which impose a minimal burden on the publication process.;,citation_author=Joseph P. Simmons;,citation_author=Leif D. Nelson;,citation_author=Uri Simonsohn;,citation_publication_date=2011-11;,citation_cover_date=2011-11;,citation_year=2011;,citation_issue=11;,citation_doi=10.1177/0956797611417632;,citation_issn=1467-9280;,citation_pmid=22006061;,citation_volume=22;,citation_language=en-US;,citation_journal_title=Psychological Science;">
<meta name="citation_reference" content="citation_title=P-curve: A key to the file-drawer.;,citation_abstract=Because scientists tend to report only studies (publication bias) or analyses (p-hacking) that “work,” readers must ask, “Are these effects true, or do they merely reflect selective reporting?” We introduce p-curve as a way to answer this question. P-curve is the distribution of statistically significant p values for a set of studies (ps &amp;amp;amp;lt; .05). Because only true effects are expected to generate right-skewed p-curves—containing more low (.01s) than high (.04s) significant p values—only right-skewed p-curves are diagnostic of evidential value. By telling us whether we can rule out selective reporting as the sole explanation for a set of findings, p-curve offers a solution to the age-old inferential problems caused by file-drawers of failed studies and analyses. (PsycInfo Database Record (c) 2025 APA, all rights reserved);,citation_author=Uri Simonsohn;,citation_author=Leif D. Nelson;,citation_author=Joseph P. Simmons;,citation_publication_date=2014-04;,citation_cover_date=2014-04;,citation_year=2014;,citation_issue=2;,citation_doi=10.1037/a0033242;,citation_issn=1939-2222;,citation_volume=143;,citation_language=en-US;,citation_journal_title=Journal of Experimental Psychology: General;,citation_publisher=American Psychological Association;">
<meta name="citation_reference" content="citation_title=Covariate adjustment had similar benefits in small and large randomized controlled trials;,citation_abstract=Objectives Covariate adjustment is a standard statistical approach in the analysis of randomized controlled trials. We aimed to explore whether the benefit of covariate adjustment on statistical significance and power differed between small and large trials, where chance imbalance in prognostic factors necessarily differs. Study Design and Setting We studied two large trial data sets [Global Use of Strategies to Open Occluded Coronary Arteries (GUSTO-I), N&nbsp;=&nbsp;30,510 and International Stroke Trial (IST), N&nbsp;=&nbsp;18,372] repeatedly drawing random samples (500,000 times) of sizes 300 and 5,000 per arm and simulated each primary outcome using the control arms. We empirically determined the treatment effects required to fix power at 80% for all unadjusted analyses and calculated the joint probabilities in the discordant cells when cross-classifying adjusted and unadjusted results from logistic regression models (ie, P&nbsp;$&amp;amp;amp;lt;~$0.05 vs. P&nbsp;$\geq~$0.05). Results The power gained from an adjusted analysis for small and large samples was between 5% and 6%. Similar proportions of discordance were noted irrespective of the sample size in both the GUSTO-I and the IST data sets. Conclusion The proportions of change in statistical significance from covariate adjustment of strongly prognostic characteristics were the same for small and large trials with similar gains in statistical power. Covariate adjustment is equally recommendable in small and large trials.;,citation_author=Douglas D. Thompson;,citation_author=Hester F. Lingsma;,citation_author=William N. Whiteley;,citation_author=Gordon D. Murray;,citation_author=Ewout W. Steyerberg;,citation_publication_date=2015-09;,citation_cover_date=2015-09;,citation_year=2015;,citation_issue=9;,citation_doi=10.1016/j.jclinepi.2014.11.001;,citation_issn=0895-4356;,citation_volume=68;,citation_journal_title=Journal of Clinical Epidemiology;">
<meta name="citation_reference" content="citation_title=P-Curve and Effect Size: Correcting for Publication Bias Using Only Significant Results;,citation_author=Uri Simonsohn;,citation_author=Leif D. Nelson;,citation_author=Joseph P. Simmons;,citation_publication_date=2014-11;,citation_cover_date=2014-11;,citation_year=2014;,citation_issue=6;,citation_doi=10.1177/1745691614553988;,citation_volume=9;,citation_journal_title=Perspectives on Psychological Science;">
<meta name="citation_reference" content="citation_title=ANCOVA versus change from baseline had more power in randomized studies and more bias in nonrandomized studies;,citation_abstract=Background and Objective: For inferring a treatment effect from the difference between a treated and untreated group on a quantitative outcome measured before and after treatment, current methods are analysis of covariance (ANCOVA) of the outcome with the baseline as covariate, and analysis of variance (ANOVA) of change from baseline. This article compares both methods on power and bias, for randomized and nonrandomized studies. Methods: The methods are compared by writing both as a regression model and as a repeated measures model, and are applied to a nonrandomized study of preventing depression. Results: In randomized studies both methods are unbiased, but ANCOVA has more power. If treatment assignment is based on the baseline, only ANCOVA is unbiased. In nonrandomized studies with preexisting groups differing at baseline, the two methods cannot both be unbiased, and may contradict each other. In the study of depression, ANCOVA suggests absence, but ANOVA of change suggests presence, of a treatment effect. The methods differ because ANCOVA assumes absence of a baseline difference. Conclusion: In randomized studies and studies with treatment assignment depending on the baseline, ANCOVA must be used. In nonrandomized studies of preexisting groups, ANOVA of change seems less biased than ANCOVA, but two control groups and two baseline measurements are recommended.;,citation_author=Gerard Van Breukelen;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_volume=59;,citation_journal_title=Journal of Clinical Epidemiology;">
</head>

<body>

<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Evaluating Methods for Covariate Selection in Experimental Designs</h1>
          </div>

    
    <div class="quarto-title-meta-container">
      <div class="quarto-title-meta-column-start">
            <div class="quarto-title-meta-author">
          <div class="quarto-title-meta-heading">Authors</div>
          <div class="quarto-title-meta-heading">Affiliation</div>
          
                <div class="quarto-title-meta-contents">
            <p class="author">Lauren Khoury </p>
          </div>
                <div class="quarto-title-meta-contents">
                    <p class="affiliation">
                        Department of Psychology, University of Wisconsin-Madison
                      </p>
                  </div>
                      <div class="quarto-title-meta-contents">
            <p class="author">Kendra Wyant </p>
          </div>
                <div class="quarto-title-meta-contents">
                    <p class="affiliation">
                        Department of Psychology, University of Wisconsin-Madison
                      </p>
                  </div>
                      <div class="quarto-title-meta-contents">
            <p class="author">Markus Brauer </p>
          </div>
                <div class="quarto-title-meta-contents">
                    <p class="affiliation">
                        Department of Psychology, University of Wisconsin-Madison
                      </p>
                  </div>
                      <div class="quarto-title-meta-contents">
            <p class="author">John J. Curtin <a href="mailto:jjcurtin@wisc.edu" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
          </div>
                <div class="quarto-title-meta-contents">
                    <p class="affiliation">
                        Department of Psychology, University of Wisconsin-Madison
                      </p>
                  </div>
                    </div>
        
        <div class="quarto-title-meta">

                      
                <div>
            <div class="quarto-title-meta-heading">Published</div>
            <div class="quarto-title-meta-contents">
              <p class="date">October 23, 2025</p>
            </div>
          </div>
          
                
              </div>
      </div>
      <div class="quarto-title-meta-column-end quarto-other-formats-target">
      <div class="quarto-alternate-formats"><div class="quarto-title-meta-heading">Other Formats</div><div class="quarto-title-meta-contents"><p><a href="index.docx"><i class="bi bi-file-word"></i>MS Word</a></p></div></div></div>
    </div>

    <div>
      <div class="abstract">
        <div class="block-title">Abstract</div>
        <p>Abstract of paper goes here and can span several lines.</p>
      </div>
    </div>


    <div class="quarto-other-links-text-target">
    </div>  </div>
</header><div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#methods" id="toc-methods" class="nav-link" data-scroll-target="#methods">Methods</a>
  <ul class="collapse">
  <li><a href="#covariate-selection-methods" id="toc-covariate-selection-methods" class="nav-link" data-scroll-target="#covariate-selection-methods">Covariate Selection Methods</a></li>
  <li><a href="#research-settings" id="toc-research-settings" class="nav-link" data-scroll-target="#research-settings">Research Settings</a></li>
  <li><a href="#data-analytic-plan" id="toc-data-analytic-plan" class="nav-link" data-scroll-target="#data-analytic-plan">Data Analytic Plan</a></li>
  </ul></li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results">Results</a>
  <ul class="collapse">
  <li><a href="#type-i-error" id="toc-type-i-error" class="nav-link" data-scroll-target="#type-i-error">Type I Error</a></li>
  <li><a href="#type-ii-error" id="toc-type-ii-error" class="nav-link" data-scroll-target="#type-ii-error">Type II Error</a></li>
  <li><a href="#parameter-estimates" id="toc-parameter-estimates" class="nav-link" data-scroll-target="#parameter-estimates">Parameter Estimates</a></li>
  </ul></li>
  <li><a href="#discussion" id="toc-discussion" class="nav-link" data-scroll-target="#discussion">Discussion</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
<div class="quarto-alternate-notebooks"><h2>Notebooks</h2><ul><li><a href="notebooks\mak_figures-preview.html"><i class="bi bi-journal-code"></i>Make Figures for Main Manuscript</a></li><li><a href="notebooks\mak_tables-preview.html"><i class="bi bi-journal-code"></i>Make Tables for Main Manuscript</a></li><li><a href="notebooks\supplement-preview.html"><i class="bi bi-journal-code"></i>Supplemental Material</a></li></ul></div></nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
</div>
<main class="content quarto-banner-title-block" id="quarto-document-content">



  


<!-- Outlets:
Psychological Science (first choice)
- 2,000 word limit for intro/discussion/notes/acknowledgements/appendices
- No word count for Methods and Results, but they encourage no more than 2,500 words 
- No figure/table limit
- 40 reference limit
- Open access option ($1000 extra)


Plos One
- No word count or figure limit
- Open access journal ($2000 - $3000)
-->
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Psychology researchers are often interested in experimental manipulations as a means of establishing causal relationships between a variable of interest and a psychological outcome. For example, researchers may manipulate treatment conditions to determine whether a new psychotherapy intervention reduces anxiety symptoms.</p>
<p>Valid causal interpretations require adequate statistical power <span class="citation" data-cites="cohenStatisticalPowerAnalysis1988 cohenPowerPrimer1992">(<a href="#ref-cohenStatisticalPowerAnalysis1988" role="doc-biblioref">Cohen 1988</a>, <a href="#ref-cohenPowerPrimer1992" role="doc-biblioref">1992</a>)</span>. Statistical power is the probability of avoiding a Type II error, or failing to reject the null hypothesis when a true effect exists. The field has increasingly recognized the critical importance of adequately powered studies. Low-powered studies do not replicate well. They have a low probability of finding true effects and when an effect is detected, the magnitude of the effect is often inflated and the likelihood that the finding is a true positive is low <span class="citation" data-cites="cohenStatisticalPowerAbnormalsocial1962 buttonPowerFailureWhy2013">(<a href="#ref-cohenStatisticalPowerAbnormalsocial1962" role="doc-biblioref">Cohen 1962</a>; <a href="#ref-buttonPowerFailureWhy2013" role="doc-biblioref">Button et al. 2013</a>)</span>. These concerns have led to a replication crisis and have prompted increased caution and consideration around researcher decisions in statistical tests.</p>
<p>Adding covariates, variables measured at baseline prior to the manipulation, to statistical models has been shown to reduce Type II error by accounting for unexplained variance in the outcome that might otherwise be interpreted as noise <span class="citation" data-cites="thompsonCovariateAdjustmentHad2015 hernandezCovariateAdjustmentRandomized2004 hernandezRandomizedControlledTrials2006 kahanRisksRewardsCovariate2014 vanbreukelenANCOVAChangeBaseline2006 egbewaleBiasPrecisionStatistical2014">(<a href="#ref-thompsonCovariateAdjustmentHad2015" role="doc-biblioref">Thompson et al. 2015</a>; <a href="#ref-hernandezCovariateAdjustmentRandomized2004" role="doc-biblioref">Adrián V. Hernández, Steyerberg, and Habbema 2004</a>; <a href="#ref-hernandezRandomizedControlledTrials2006" role="doc-biblioref">Adrián V. Hernández, Eijkemans, and Steyerberg 2006</a>; <a href="#ref-kahanRisksRewardsCovariate2014" role="doc-biblioref">Kahan et al. 2014</a>; <a href="#ref-vanbreukelenANCOVAChangeBaseline2006" role="doc-biblioref">Van Breukelen 2006</a>; <a href="#ref-egbewaleBiasPrecisionStatistical2014" role="doc-biblioref">Egbewale, Lewis, and Sim 2014</a>)</span>. In the earlier example, where researchers test whether a new treatment reduces anxiety symptoms, they might consider including a measure of recent stressful life events as a covariate. Stressful events are expected to correlate with anxiety but, if measured after treatment assignment, would not be correlated with the manipulated variable thereby reducing variance in anxiety that is unrelated to the manipulation.</p>
<p>However, selecting which covariates to include is not straightforward. As a result, researchers have often iterated over their analyses, selectively adding covariates that improve the statistical significance (i.e., <em>p</em>-value) of their focal variable. This is a practice known as <em>p</em>-hacking <span class="citation" data-cites="simonsohnPcurveKeyFiledrawer2014">(<a href="#ref-simonsohnPcurveKeyFiledrawer2014" role="doc-biblioref">Simonsohn, Nelson, and Simmons 2014</a>)</span>. It is now well-established that this is a statistically invalid method for covariate selection and leads to an increased Type I error rate (i.e., finding significant effects that do not truly exist; <span class="citation" data-cites="simmonsFalsepositivePsychologyUndisclosed2011 ioannidisWhyMostPublished2005 schelchterPosthocSelectionCovariates1985 beachChoosingCovariatesAnalysis1989">(<a href="#ref-simmonsFalsepositivePsychologyUndisclosed2011" role="doc-biblioref">Simmons, Nelson, and Simonsohn 2011</a>; <a href="#ref-ioannidisWhyMostPublished2005" role="doc-biblioref">Ioannidis 2005</a>; <a href="#ref-schelchterPosthocSelectionCovariates1985" role="doc-biblioref">Schelchter and Forsythe 1985</a>; <a href="#ref-beachChoosingCovariatesAnalysis1989" role="doc-biblioref">Beach and Meier 1989</a>)</span>).</p>
<p>While this serves as an example of what not to do, there remains an important question on how covariates should be selected. In light of the serious consequences of <em>p</em>-hacking, as highlighted by <span class="citation" data-cites="simmonsFalsepositivePsychologyUndisclosed2011">Simmons, Nelson, and Simonsohn (<a href="#ref-simmonsFalsepositivePsychologyUndisclosed2011" role="doc-biblioref">2011</a>)</span> and others, one might conclude that perhaps no covariates should be used. Though, as noted earlier, this would increase the risk of Type II error. Another conclusion might be to use all available covariates that are reasonably believed to account for unexplained variance in the outcome. Each additional covariate, however, reduces degrees of freedom. In psychology, where potential covariates are numerous and often redundant, this can unnecessarily reduce degrees of freedom, again increasing the risk of Type II error.</p>
<p>It is clear, then, that covariate selection is essential for adequately powered analyses (i.e., those with low Type II error). An optimal covariate selection method will be able to select the covariates that provide the highest increase in power (e.g., covariates highly correlated with the outcome <span class="citation" data-cites="kahanRisksRewardsCovariate2014">(<a href="#ref-kahanRisksRewardsCovariate2014" role="doc-biblioref">Kahan et al. 2014</a>)</span>) with the lowest cost to degrees of freedom (e.g., by including covariates that contribute to unique reductions in variance). Criticially the method of covariate selection must also not nominally inflate the Type I error rate, as occurs with <em>p</em>-hacking.</p>
<p>This study aims to provide clear and accessible methods for researchers to select among a set of covariates. Specifically, we conducted 40,000 simulations of nine candidate methods across several research settings. These settings varied in population parameter, sample size, number of available covariates, proportion of good covariates, and the strength of relationships between good covariates and the outcome. We report Type I and Type II error rates for methods that use no covariates, all available covariates, a statistically invalid selection method (<em>p</em>-hacking), and three valid selection methods (Pearson correlation, full linear model, and least absolute shrinkage and selection operator [LASSO]) that were eached tested with and without controlling for the focal variable. These findings can help researchers determine the optimal covariate selection method for their specific research setting.</p>
</section>
<section id="methods" class="level1">
<h1>Methods</h1>
<section id="covariate-selection-methods" class="level2">
<h2 class="anchored" data-anchor-id="covariate-selection-methods">Covariate Selection Methods</h2>
<p>We evaluated nine linear regression models with varying levels and methods of covariate selection. Two models did not use any covariate selection: a linear regression model that used no covariates and a linear regression model that used all available covariates. One model used a statistically invalid method of selecting covariates based on whether they lower the regression p-value (i.e., p-hacking). The remaining six models used three systematic covariate selection methods, selection based on the Pearson correlation coefficient (<em>r</em>), a full linear model, and LASSO, controlling for the focal manipulation (i.e., <em>X</em>) and without controlling for <em>X</em>. A summary of the nine models is presented in <a href="#tbl-methods" class="quarto-xref">Table&nbsp;1</a>.</p>
<div class="quarto-embed-nb-cell">
<div class="cell">
<div id="tbl-methods" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-methods-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: The nine linear regression models and their definition for covariate selection.
</figcaption>
<div aria-describedby="tbl-methods-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output cell-output-display">
<table class="lightable-classic do-not-create-environment cell caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">Method</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">Definition</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">No covariates</td>
<td style="text-align: left;">Y is regressed on X without any covariates.</td>
</tr>
<tr class="even">
<td style="text-align: left;">All covariates</td>
<td style="text-align: left;">All available covariates are included in the regression model.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">P-hacking</td>
<td style="text-align: left;">Unsystematically adding covariates based on whether they lower the p-value of the main effect of X on Y.</td>
</tr>
<tr class="even">
<td style="text-align: left;">Bivariate correlation</td>
<td style="text-align: left;">Pearson correlation coefficient (r) of covariates on Y. Covariates are considered one at a time and included in the final model if they yield a significant effect on Y (p &lt; .05).</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Partial correlation</td>
<td style="text-align: left;">Pearson correlation coefficient (r) of covariates on Y while controlling for X. Covariates are considered one at a time and included in the final model if they yield a significant effect on Y (p &lt; .05).</td>
</tr>
<tr class="even">
<td style="text-align: left;">Full linear model</td>
<td style="text-align: left;">A full linear model that regresses Y on all available covariates. Covariates that have a statistically significant effect on Y (p &lt; .05) are retained.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Full linear model with X</td>
<td style="text-align: left;">A full linear model that regresses Y on all available covariates and X. Covariates that have a statistically significant effect on Y (p &lt; .05) when controlling for X are retained.</td>
</tr>
<tr class="even">
<td style="text-align: left;">LASSO</td>
<td style="text-align: left;">A linear model that regresses Y on all available covariates and applies a penalty to shrink coefficients for less important covariates, potentially dropping them altogether (i.e., coefficient of 0). Covariates with non-zero coefficients were retained.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">LASSO with X</td>
<td style="text-align: left;">A linear model that regresses Y on all available covariates and applies a penalty to shrink coefficients for less important covariates. We assigned a 0 penalty to X to retain it in the model. Covariates with non-zero coefficients when controlling for X were retained.</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
</div>
</section>
<section id="research-settings" class="level2">
<h2 class="anchored" data-anchor-id="research-settings">Research Settings</h2>
<!--consider adding citations throughout this section to justify some of our decisions-->
<p>We manipulated several variables designed to mimic varying research settings that psychology researchers might be working in. We crossed all levels of each variable to create a total of 540 unique research settings. A summary of these settings is presented in <a href="#tbl-dictionary" class="quarto-xref">Table&nbsp;2</a>. The variables include:</p>
<ol type="1">
<li><p>The true population parameter for X. We selected values that represent null (<span class="math inline">\(b_x = 0\)</span>), medium (<span class="math inline">\(b_x = 0.3\)</span>) and large (<span class="math inline">\(b_x = 0.5\)</span>) effect sizes.</p></li>
<li><p>The sample size. We chose values for the number of observations that pertain to common sample sizes in experimental research: 50, 100, 150, 200, 300, and 400 observations.</p></li>
<li><p>The number of covariates available. We selected a wide range of possible scenarios: 4, 8, 12, 16, or 20 covariates.</p></li>
<li><p>The proportion of “good” covariates. We used varying proportions of good covariates across research settings (.25, .50, and .75) to represent a common reality when a researcher is faced with many covariates, but only some may be related to their outcome.</p></li>
<li><p>The strength of the relationship between the good covariates and Y. All good covariates were given a moderate and large relationship to <em>Y</em>, correlations of 0.3 and 0.5, respectively. Since these good covariates are all correlated with <em>Y</em>, it is likeley they are also correlated with each other. Therefore we assigned a moderate 0.3 correlation for all relationships among good covariates.</p></li>
</ol>
<div class="quarto-embed-nb-cell">
<div class="cell">
<div id="tbl-dictionary" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-dictionary-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;2: Research setting variables and values
</figcaption>
<div aria-describedby="tbl-dictionary-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output cell-output-display">
<table class="table table-striped table-hover do-not-create-environment cell caption-top table-sm small" data-quarto-postprocess="true">
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">Research Setting Variable</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">Values</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left; width: 15em;">The population parameter for X</td>
<td style="text-align: left; width: 10em;">0, 0.3, 0.5</td>
</tr>
<tr class="even">
<td style="text-align: left; width: 15em;">The number of observations in the sample</td>
<td style="text-align: left; width: 10em;">50, 100, 150, 200, 300, 400</td>
</tr>
<tr class="odd">
<td style="text-align: left; width: 15em;">The number of covariates</td>
<td style="text-align: left; width: 10em;">4, 8, 12, 16, 20</td>
</tr>
<tr class="even">
<td style="text-align: left; width: 15em;">The proportion of "good" covariates</td>
<td style="text-align: left; width: 10em;">0.25, 0.50, 0.75</td>
</tr>
<tr class="odd">
<td style="text-align: left; width: 15em;">The correlation between Y and good covariates</td>
<td style="text-align: left; width: 10em;">0.3, 0.5</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
</div>
</section>
<section id="data-analytic-plan" class="level2">
<h2 class="anchored" data-anchor-id="data-analytic-plan">Data Analytic Plan</h2>
<p>All data analyses were done in R (version 4.4.2). Simulations were run using high-throughput computing resources provided by the University of Wisconsin-Madison Center for High Throughput Computing <span class="citation" data-cites="chtc">(<a href="#ref-chtc" role="doc-biblioref">Center for High Throughput Computing 2006</a>)</span>.</p>
<p>We ran 40,000 simulations for each research setting. Within each simulation we generated a unique datset that consisted of a dichotomous focal variable (<em>X</em>), varying numbers of quantitative covariates, where a subset are correlated with each other and with <em>Y</em> (see Research Settings section), and a quantitative outcome (<em>Y</em>) calculated by adding the <em>X</em> variable multiplied by the effect size (i.e., population parameter) to the <em>Y</em> generated from the correlation matrix with the covariates. We fit models from our nine methods on each simulated dataset. From each model we saved out the parameter estimate, standard error, and p-value for <em>X</em>. We also calculated true and false positive rates to evaluate the rate at which the model selected covariates correlated with <em>Y</em> (i.e., percentage of good covariates selected) and incorrectly selected covariates not correlated with <em>Y</em> (i.e., percentage of bad covariates selected).</p>
<p>For research settings where the population parameter for <em>X</em> is 0 (i.e., <em>X</em> has no effect on <em>Y</em>), we report the Type I error rate for each method both across and within research settings. For research settings where the population parameter for <em>X</em> is 0.3 or 0.5 (i.e., <em>X</em> has an effect on <em>Y</em>), we report the Type II error rate for each method across and within research settings. We also provide sampling distributions of the parameter estimate for <em>X</em> across research settings for each method, separately by true effect size (0, 0.3, and 0.5). Detailed tables of range and average error rates for each research setting and true and false positive rates for covariates are available in the supplement.</p>
</section>
</section>
<section id="results" class="level1">
<h1>Results</h1>
<section id="type-i-error" class="level2">
<h2 class="anchored" data-anchor-id="type-i-error">Type I Error</h2>
<p>Since this is simulation study, we were able to set the true population parameter for <em>X</em> to be zero (i.e., <span class="math inline">\(b_x = 0\)</span>). Therefore, any significant result found was a Type I error. <a href="#fig-bar-1" class="quarto-xref">Figure&nbsp;1</a> shows the average Type I error rate across all research settings for each method. The p-hacking method for selecting covariates, unsurprisingly led to a highly inflated Type I error rate, consistent with the extant research published in the last several years on the connection between researcher degrees of freedom and false positives. Most other methods remained around the expected .05 threshold. There was some elevation in Type I errors for methods that controlled for <em>X</em> compared to those, however, it is not clear that these differences are substantial.</p>
<div class="quarto-embed-nb-cell">
<div id="cell-fig-bar-1" class="cell">
<div class="cell-output cell-output-display">
<div id="fig-bar-1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-bar-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="index_files/figure-html/notebooks-mak_figures-fig-bar-1-output-2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Figure&nbsp;1: Type I Error by Method. Average type I error rate across all research settings is displayed for each method separately by color. Dashed line depicts expected Type I error rate for .05 alpha."><img src="index_files/figure-html/notebooks-mak_figures-fig-bar-1-output-2.png" width="672" height="480" class="figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-bar-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Type I Error by Method. Average type I error rate across all research settings is displayed for each method separately by color. Dashed line depicts expected Type I error rate for .05 alpha.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p>We assessed Type I error by individual research setting and found several patterns (<a href="#fig-type1-panel" class="quarto-xref">Figure&nbsp;2</a>). First, small sample sizes are more susceptible to inflated Type I error rates when using covariate selection methods that control for <em>X</em>. As sample sizes get larger (i.e., <em>n</em> = 300), the methods become comparable. Second, as the number of available covariates to select from increases, Type I error rate increases for covariate selection methods that control for <em>X</em>, such as a full linear model with <em>X</em> and LASSO with <em>X</em>, and to a lesser degree partial correlation. Third, there appeared to be no definitive pattern in Type I error rate as the proportion of good covariates increased<!--maybe error of LASSO decreases slightly and error of full linear model increases?-->. Similarly we did not see changes in Type I error rate as function of the correlation strength between covariates and <em>Y</em>.</p>
<div class="quarto-embed-nb-cell">
<div id="cell-fig-type1-panel" class="cell" data-fig-height="6" data-fig-width="8">
<div class="cell-output cell-output-display">
<div id="fig-type1-panel" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-type1-panel-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="index_files/figure-html/notebooks-mak_figures-fig-type1-panel-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Figure&nbsp;2: Type I error by method and research setting. Plots are paneled by aspects of the research setting (number of observations, number of covariates, proportioin of good covariates, and Y-covariate correlation strength). Methods are displayed separately by color. Methods with no covariate selection are depicted as solid lines. p-hacking is depicted as dashed line. Covariate selection methods that control for X are depicted as two dash lines. Covariate selection methods that do not control for X are depicted as long dash lines."><img src="index_files/figure-html/notebooks-mak_figures-fig-type1-panel-output-1.png" width="768" height="576" class="figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-type1-panel-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Type I error by method and research setting. Plots are paneled by aspects of the research setting (number of observations, number of covariates, proportioin of good covariates, and Y-covariate correlation strength). Methods are displayed separately by color. Methods with no covariate selection are depicted as solid lines. p-hacking is depicted as dashed line. Covariate selection methods that control for X are depicted as two dash lines. Covariate selection methods that do not control for X are depicted as long dash lines.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
</section>
<section id="type-ii-error" class="level2">
<h2 class="anchored" data-anchor-id="type-ii-error">Type II Error</h2>
<p>We simulated datasets with two possible population parameters for the effect of <em>X</em> on <em>Y</em> (<span class="math inline">\(b_x = 0.3\)</span>, <span class="math inline">\(b_x = 0.5\)</span>). Any non-significant result found indicated a Type II error. Stronger statistical methods will have lower Type II error (implying greater statistical power). Since we demonstrated that p-hacking substantially inflates Type I error, making it a statistically invalid method for covariate selection, we do not evaluate Type II Error for this method. <a href="#fig-bar-2" class="quarto-xref">Figure&nbsp;3</a> shows the average Type II error rate across all research settings for each method. Using no covariates results in the highest Type II error highlighting the importance of covariates for detecting true effects. Type II error rates trended lower for covariate selection methods that controlled for <em>X</em> compared to those that did not control for <em>X</em>.</p>
<div class="quarto-embed-nb-cell">
<div id="cell-fig-bar-2" class="cell">
<div class="cell-output cell-output-display">
<div id="fig-bar-2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-bar-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="index_files/figure-html/notebooks-mak_figures-fig-bar-2-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Figure&nbsp;3: Type II Error by Method. Average type II error rate across all research settings is displayed for each method separately by color."><img src="index_files/figure-html/notebooks-mak_figures-fig-bar-2-output-1.png" width="672" height="480" class="figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-bar-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Type II Error by Method. Average type II error rate across all research settings is displayed for each method separately by color.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p>We also assessed Type II error by individual research setting (<a href="#fig-panel-2" class="quarto-xref">Figure&nbsp;4</a>). Across all research setting, using no covariates was associated with higher Type II error. Using all available covariates or selection methods that do not control for <em>X</em> performed had higher Type II error rates compared to the other methods when sample sizes were low. This pattern was especially notable for using all covariates and a full linear model without <em>X</em>. As sample size increased, the methods performed comparably with respect to Type II error. Using all covariates or a full linear model without <em>X</em> for selection produced higher Type II error rates compared to other methods when there was a larger number of covariates available. The full linear model without <em>X</em> also produced higher Type II error rates, compared to other methods when the proportion of good covariates was higher.</p>
<div class="quarto-embed-nb-cell">
<div id="cell-fig-panel-2" class="cell" data-fig-height="9" data-fig-width="7.5">
<div class="cell-output cell-output-display">
<div id="fig-panel-2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-panel-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="index_files/figure-html/notebooks-mak_figures-fig-panel-2-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Figure&nbsp;4: Type II error by method and research setting. Plots are paneled by aspects of the research setting (number of observations, number of covariates, proportioin of good covariates, Y-covariate correlation strength, and population parameter for X). Methods are displayed separately by color. Methods with no covariate selection are depicted as solid lines. Covariate selection methods that control for X are depicted as two dash lines. Covariate selection methods that do not control for X are depicted as long dash lines."><img src="index_files/figure-html/notebooks-mak_figures-fig-panel-2-output-1.png" width="720" height="864" class="figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-panel-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Type II error by method and research setting. Plots are paneled by aspects of the research setting (number of observations, number of covariates, proportioin of good covariates, Y-covariate correlation strength, and population parameter for X). Methods are displayed separately by color. Methods with no covariate selection are depicted as solid lines. Covariate selection methods that control for X are depicted as two dash lines. Covariate selection methods that do not control for X are depicted as long dash lines.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
</section>
<section id="parameter-estimates" class="level2">
<h2 class="anchored" data-anchor-id="parameter-estimates">Parameter Estimates</h2>
<p><a href="#fig-distribution-bx" class="quarto-xref">Figure&nbsp;5</a> shows the sampling distribution for the parameter estimate of <em>X</em> for all nine methods separately by effect size (<span class="math inline">\(b_x = 0\)</span>, <span class="math inline">\(b_x = 0.3\)</span>, <span class="math inline">\(b_x = 0.5\)</span>). Distributions for parameter estimates for all methods are centered around the true population values. Using no covariates produces a wider distribution, indicating more variability in its parameter estimates. The top plot also highlights an unusual feature of p-hacking. When there is no true effect the distribution appears bimodal due to the artificial inflation or deflation of parameter estimates that occurs when selecting covariates to obtain a significant p-value.</p>
<div class="quarto-embed-nb-cell">
<div id="cell-fig-distribution-bx" class="cell" data-fig-height="8">
<div class="cell-output cell-output-display">
<div id="fig-distribution-bx" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-distribution-bx-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="index_files/figure-html/notebooks-mak_figures-fig-distribution-bx-output-2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Figure&nbsp;5: Sampling Distribution for Population Parameter Estimates."><img src="index_files/figure-html/notebooks-mak_figures-fig-distribution-bx-output-2.png" width="672" height="768" class="figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-distribution-bx-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Sampling Distribution for Population Parameter Estimates.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="discussion" class="level1">
<h1>Discussion</h1>
<section id="dont-p-hack-and-other-type-1-error-conclusions" class="level4">
<h4 class="anchored" data-anchor-id="dont-p-hack-and-other-type-1-error-conclusions">1. Don’t p-hack and other type 1 error conclusions</h4>
</section>
<section id="use-covariates-and-other-type-ii-error-conclusions" class="level4">
<h4 class="anchored" data-anchor-id="use-covariates-and-other-type-ii-error-conclusions">2. Use covariates and other type II error conclusions</h4>
</section>
<section id="in-many-instances-you-can-use-all-covariates" class="level4">
<h4 class="anchored" data-anchor-id="in-many-instances-you-can-use-all-covariates">3. In many instances you can use all covariates</h4>
</section>
<section id="compare-candidate-selection-methods-r-and-partial-r---comparable-in-power-one-slight-increase-in-type-1-and-1-small-biasing-in-parameter-estimates-might-improve-power-in-certain-research-settings-low-n-large-number-of-covariates.-describe-departure-in-type-1-error-by-comparing-with-other-violations---normality-trivial" class="level4">
<h4 class="anchored" data-anchor-id="compare-candidate-selection-methods-r-and-partial-r---comparable-in-power-one-slight-increase-in-type-1-and-1-small-biasing-in-parameter-estimates-might-improve-power-in-certain-research-settings-low-n-large-number-of-covariates.-describe-departure-in-type-1-error-by-comparing-with-other-violations---normality-trivial">4. Compare candidate selection methods (R and partial R - comparable in power, one slight increase in type 1 and 1 small biasing in parameter estimates) might improve power in certain research settings (low n, large number of covariates). Describe departure in type 1 error by comparing with other violations - normality (trivial)</h4>
</section>
<section id="dont-run-with-n-50-but-acknowledge-difficulty-in-reaching-conclusions" class="level4">
<h4 class="anchored" data-anchor-id="dont-run-with-n-50-but-acknowledge-difficulty-in-reaching-conclusions">5. Don’t run with n = 50 but acknowledge difficulty in reaching conclusions</h4>
</section>
<section id="alternative-type-of-covariate-not-addressed-in-this-study---measured-covariates-after-baseline-reasonably-sure-that-they-were-not-affected-by-x.-another-use-of-covariates-is-for-controlling-but-that-is-different-and-more-complicated." class="level4">
<h4 class="anchored" data-anchor-id="alternative-type-of-covariate-not-addressed-in-this-study---measured-covariates-after-baseline-reasonably-sure-that-they-were-not-affected-by-x.-another-use-of-covariates-is-for-controlling-but-that-is-different-and-more-complicated.">6. Alternative type of covariate not addressed in this study - Measured covariates after baseline (reasonably sure that they were not affected by x). Another use of covariates is for controlling but that is different and more complicated.</h4>
<!-- ### 7. Finding good covariates?  -->
</section>
<section id="why-we-get-biased-parameter-estimates-with-x" class="level4">
<h4 class="anchored" data-anchor-id="why-we-get-biased-parameter-estimates-with-x">7. Why we get biased parameter estimates with x</h4>
</section>
<section id="final-conclusions" class="level4">
<h4 class="anchored" data-anchor-id="final-conclusions">8. Final Conclusions</h4>
</section>
</section>
<section id="references" class="level1 unnumbered">


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-beachChoosingCovariatesAnalysis1989" class="csl-entry" role="listitem">
Beach, M. L., and P. Meier. 1989. <span>“Choosing Covariates in the Analysis of Clinical Trials.”</span> <em>Controlled Clinical Trials</em> 10 (4 Suppl): 161S–175S. <a href="https://doi.org/10.1016/0197-2456(89)90055-x">https://doi.org/10.1016/0197-2456(89)90055-x</a>.
</div>
<div id="ref-buttonPowerFailureWhy2013" class="csl-entry" role="listitem">
Button, Katherine S., John P. A. Ioannidis, Claire Mokrysz, Brian A. Nosek, Jonathan Flint, Emma S. J. Robinson, and Marcus R. Munafò. 2013. <span>“Power Failure: Why Small Sample Size Undermines the Reliability of Neuroscience.”</span> <em>Nature Reviews Neuroscience</em> 14 (5): 365–76. <a href="https://doi.org/10.1038/nrn3475">https://doi.org/10.1038/nrn3475</a>.
</div>
<div id="ref-chtc" class="csl-entry" role="listitem">
Center for High Throughput Computing. 2006. <span>“Center for High Throughput Computing.”</span> Center for High Throughput Computing. <a href="https://doi.org/10.21231/GNT1-HW21">https://doi.org/10.21231/GNT1-HW21</a>.
</div>
<div id="ref-cohenStatisticalPowerAbnormalsocial1962" class="csl-entry" role="listitem">
Cohen, Jacob. 1962. <span>“The Statistical Power of Abnormal-Social Psychological Research: <span>A</span> Review.”</span> <em>The Journal of Abnormal and Social Psychology</em> 65 (3): 145–53. <a href="https://doi.org/10.1037/h0045186">https://doi.org/10.1037/h0045186</a>.
</div>
<div id="ref-cohenStatisticalPowerAnalysis1988" class="csl-entry" role="listitem">
———. 1988. <em>Statistical <span>Power Analysis</span> for the <span>Behavioral Sciences</span></em>. 2 edition. Hillsdale, N.J: Routledge.
</div>
<div id="ref-cohenPowerPrimer1992" class="csl-entry" role="listitem">
———. 1992. <span>“A Power Primer.”</span> <em>Psychological Bulletin</em> 112 (1): 155–59.
</div>
<div id="ref-egbewaleBiasPrecisionStatistical2014" class="csl-entry" role="listitem">
Egbewale, Bolaji E., Martyn Lewis, and Julius Sim. 2014. <span>“Bias, Precision and Statistical Power of Analysis of Covariance in the Analysis of Randomized Trials with Baseline Imbalance: A Simulation Study.”</span> <em>BMC Medical Research Methodology</em> 14 (1): 49. <a href="https://doi.org/10.1186/1471-2288-14-49">https://doi.org/10.1186/1471-2288-14-49</a>.
</div>
<div id="ref-hernandezRandomizedControlledTrials2006" class="csl-entry" role="listitem">
Hernández, Adrián V., Marinus J. C. Eijkemans, and Ewout W. Steyerberg. 2006. <span>“Randomized <span class="nocase">Controlled Trials With Time-to-Event Outcomes</span>: <span>How Much Does Prespecified Covariate Adjustment Increase Power</span>?”</span> <em>Annals of Epidemiology</em> 16 (1): 41–48. <a href="https://doi.org/10.1016/j.annepidem.2005.09.007">https://doi.org/10.1016/j.annepidem.2005.09.007</a>.
</div>
<div id="ref-hernandezCovariateAdjustmentRandomized2004" class="csl-entry" role="listitem">
Hernández, Adrián V, Ewout W Steyerberg, and J. Dik F Habbema. 2004. <span>“Covariate Adjustment in Randomized Controlled Trials with Dichotomous Outcomes Increases Statistical Power and Reduces Sample Size Requirements.”</span> <em>Journal of Clinical Epidemiology</em> 57 (5): 454–60. <a href="https://doi.org/10.1016/j.jclinepi.2003.09.014">https://doi.org/10.1016/j.jclinepi.2003.09.014</a>.
</div>
<div id="ref-ioannidisWhyMostPublished2005" class="csl-entry" role="listitem">
Ioannidis, John P. A. 2005. <span>“Why Most Published Research Findings Are False.”</span> <em>PLoS Medicine</em> 2 (8): e124. <a href="https://doi.org/10.1371/journal.pmed.0020124">https://doi.org/10.1371/journal.pmed.0020124</a>.
</div>
<div id="ref-kahanRisksRewardsCovariate2014" class="csl-entry" role="listitem">
Kahan, Brennan C, Vipul Jairath, Caroline J Doré, and Tim P Morris. 2014. <span>“The Risks and Rewards of Covariate Adjustment in Randomized Trials: An Assessment of 12 Outcomes from 8 Studies.”</span> <em>Trials</em> 15 (April): 139. <a href="https://doi.org/10.1186/1745-6215-15-139">https://doi.org/10.1186/1745-6215-15-139</a>.
</div>
<div id="ref-schelchterPosthocSelectionCovariates1985" class="csl-entry" role="listitem">
Schelchter, Mark D., and Alan B. Forsythe. 1985. <span>“Post-Hoc Selection of Covariates in Randomized Experiments.”</span> <em>Communications in Statistics - Theory and Methods</em> 14 (3): 679–99. <a href="https://doi.org/10.1080/03610928508828942">https://doi.org/10.1080/03610928508828942</a>.
</div>
<div id="ref-simmonsFalsepositivePsychologyUndisclosed2011" class="csl-entry" role="listitem">
Simmons, Joseph P., Leif D. Nelson, and Uri Simonsohn. 2011. <span>“False-Positive Psychology: Undisclosed Flexibility in Data Collection and Analysis Allows Presenting Anything as Significant.”</span> <em>Psychological Science</em> 22 (11): 1359–66. <a href="https://doi.org/10.1177/0956797611417632">https://doi.org/10.1177/0956797611417632</a>.
</div>
<div id="ref-simonsohnPcurveKeyFiledrawer2014" class="csl-entry" role="listitem">
Simonsohn, Uri, Leif D. Nelson, and Joseph P. Simmons. 2014. <span>“P-Curve: <span>A</span> Key to the File-Drawer.”</span> <em>Journal of Experimental Psychology: General</em> 143 (2): 534–47. <a href="https://doi.org/10.1037/a0033242">https://doi.org/10.1037/a0033242</a>.
</div>
<div id="ref-thompsonCovariateAdjustmentHad2015" class="csl-entry" role="listitem">
Thompson, Douglas D., Hester F. Lingsma, William N. Whiteley, Gordon D. Murray, and Ewout W. Steyerberg. 2015. <span>“Covariate Adjustment Had Similar Benefits in Small and Large Randomized Controlled Trials.”</span> <em>Journal of Clinical Epidemiology</em> 68 (9): 1068–75. <a href="https://doi.org/10.1016/j.jclinepi.2014.11.001">https://doi.org/10.1016/j.jclinepi.2014.11.001</a>.
</div>
<div id="ref-vanbreukelenANCOVAChangeBaseline2006" class="csl-entry" role="listitem">
Van Breukelen, Gerard. 2006. <span>“<span>ANCOVA</span> Versus Change from Baseline Had More Power in Randomized Studies and More Bias in Nonrandomized Studies.”</span> <em>Journal of Clinical Epidemiology</em> 59: 920–25.
</div>
</div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>