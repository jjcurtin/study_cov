---
title: Evaluating Methods for Covariate Selection
author:
  - name: Lauren Khoury
    corresponding: false
    affiliations:
      - Department of Psychology, University of Wisconsin-Madison
  - name: Kendra Wyant
    corresponding: false
    affiliations:
      - Department of Psychology, University of Wisconsin-Madison
  - name: John J. Curtin 
    corresponding: true
    email: jjcurtin@wisc.edu
    affiliations:
      - Department of Psychology, University of Wisconsin-Madison 
abstract: |
  Abstract of paper goes here and can span several lines.
date: last-modified
bibliography: references.bib
bibliographystyle: apa
number-sections: false 
editor_options: 
  chunk_output_type: console
---

# Introduction
This is how you cite a paper using the bibtex key in Zotero [@simmonsFalsepositivePsychologyUndisclosed2011].

  In Psychology research, we often use linear regression models to test if a focal variable has a significant effect on an outcome variable of interest. While we could fit a model regressing our dependent variable only on our independent variable, it would benefit us to include covariates. Covariates are variables that are not focal independent variables, but are added to a model to increase power and precision. Statistical power is the ability to find a significant effect when one truly does exist. Studies with low power do not replicate well (replication crisis). 
  
  For the purposes of this paper, consider the case where our focal variable ($X$) is an experimental manipulation. In this context, covariates are baseline measures taken before the manipulation and are therefore uncorrelated with the manipulation. They increase power to detect effects of the manipulated variable of focus. For example, if researchers were interested in testing the effects of a new treatment technique on depression, variables such as age, sex, gender identity, socioeconomic status, and education could be measured at baseline. This would increase power to find if there is a true significant effect of the new treatment. The increase in power comes from a reduction in the error of the model. Covariates reduce the standard error of the $X$ effect which yields a more precise parameter estimate. 
  
  The prevalence of possible covariates to measure in the field of Psychology is high. Ideally, only the "good" covariates should be included in statistical models. By "good" we mean a couple of things: we want variables that are uncorrelated with the focal IV and variables that explain variance in the outcome. Again, in experimental work, variables measured at baseline are not correlated with the manipulated variable.
  
  Collecting data on many covariates is the simple part, but then selecting which covariates to include in models is less simple. Some measured covariates may be redundant (i.e., explain overlapping variance in the outcome) or are not related to the outcome. (p-hacking history).  

# Method

  All computations were conducted in R, including scripts to generate data based on crossings of research setting variables, fit linear models based on different methods for covariate selection, and extract and visualize the results from these models. The process was repeated across multiple simulations via high-throughput computing.   

## Data Generation Process

  For the data generation process, we manipulated variables as shown in [@tbl-dictionary] with levels chosen that are commonly found in Psychology researh. The population parameters for $X$ were chosen to cover both zero and nonzero effects, with the nonzero effects covering a medium and larger effect size. We chose values for the number of observations that pertain to common sample sizes in experimental research. 
  
  The four variables handling the covariates were chosen with the plan of crossing all levels. Hence, the numbers of covariates had to be divisible by four to cross with the chosen levels of percentages. The values cover a range of amounts of covariates that researchers might have available to them. The percentages of "good" covariates represent the reality that while many might be available, there are varying strengths to which these covariates relate to the outcome. The number of total available covariates by the percentages of good covariates gives us the number of good covariates. This is factored into the data generating process in the covariance matrix, where there is a nonzero entry in the matrix intersection between $Y$ and each good covariate. The value for this is given by the $Y$-covariate correlation (`r_ycov`). Since these good covariates are correlated with $Y$, they must be correlated with each other. This gives a nonzero entries in the matrix intersections between the good covariates. This value is given by the covariate correlation (`r_cov`). The values for the two correlation variables (between $Y$ and the covariates and between the covariates themselves) were selected with what we feel is expected in social science contexts. These values also had to satisfy a positive-definite covariance matrix as $Y$ and the covariates were generated from a multivariate normal distribution. The $X$ variable was generated as a dichotomous variable representing an experimental manipulation (e.g., condition versus treatment). The final values for $Y$ were then calculated by adding the $Y$ generated with the covariates to the $X$ variable multiplied by the given population parameter for $X$.  
  
{{< embed notebooks/mak_tables.qmd#tbl-dictionary >}}  

## Covariate Selection 

  There are nine methods for selecting covariates to include in linear models that we evaluated. The methods can best be broken down into two categories: those that do not involve systematically selecting covariates and those that do. For the former category, we explored inlcuding (1) no covariates in the linear models and including (2) all available covariates. Here, we consider all available covariates to mean all covariates that were measured prior to manipulation. 

  For the latter category, we first employed the method of (3) p-hacking to replicate that this is not a statistically valid method to use for covariate selection. To accomplish this method, we include covariates that lower the p-value for $X$ when comparing it to the p-value from the model regressing $Y$ only on $X$. 
  
  This leaves six remaining methods that we predicted to be viable and successful methods for covariate selection. We consider the Pearson correlation coefficient ($r$) for both bivariate and partial correlations. In the (4) bivariate correlation model, we consider one covariate at a time and include it in the final model if it has a significant effect on $Y$. Note, that for this paper a significance level of $\alpha = 0.05$ is used. In the (5) partial correlation model, we consider one covariate at a time and include it in the final model if it has a significant effect on $Y$ while also controlling for $X$. We then fit full linear models in cases of including and excluding $X$. We fit a (6) full linear model regressing $Y$ on all covariates, and we included all covariates in the final model that are significant on $Y$ when controlling for $X$. Similarly, we fit a (7) full linear model without $X$, where we include all covariates significant on $Y$ without controlling for $X$. Finally, we considered a more complex approach of covariate selection by employing the least absolute shrinkage and selection operator (LASSO, also known as L1 regularization). We tuned the penalty value across 100 bootstraps, fit the best model with the penalty that yielded the lowest RMSE, and selected all covariates with nonzero coefficients for inclusion in the final linear model. This process was the same for a (8) LASSO model that had a zero penalty factor applied to $X$ (i.e., $X$ was retained in the model) and for a (9) LASSO model that did not contain $X$. 
  
  To summarize, these are the nine models compared in this paper used for covariate selection:
  
  1. No covariates
  2. All covariates
  3. P-hacking
  4. Bivariate correlation 
  5. Partial correlation
  6. Full linear model
  7. Full linear model without $X$
  8. LASSO
  9. LASSO without $X$

## Simulations

  The crossing of all levels of each variable resulted in 540 unique research settings. We ran 40,000 simulations for each unique setting using the Center for High Throughput Computing (CHTC) at the University of Wisconsin, Madison. A seed was set for each simulation for the purpose of reproducibility. Within each simulation, the scripts first generated a unique dataset based on the variables and process discussed. Then, a linear model was fit according to each of the nine aforementioned methods for covariate selection. Finally, the results from these models were saved. These results include the corresponding parameter estimate, standard error, and p-value for $X$ from the linear model. The numerator and denominator degrees of freedom were also extracted from the model. We calculated true positive rates and false positive rates to identify the rates at which the different methods correctly selected covariates that did relate to $Y$ and incorrectly selected covariates that did not relate to $Y$, respectively.   

## Data Analysis 


# Results

  The product of the sizes of the unique research settings (540), simulations (40,000), and methods (9) yielded a total of 194,400,000 observations. 

  The results will be considered first by the zero $X$ effect followed by the nonzero $X$ effects. The Type I and Type II errors will be compared across methods and across levels of research setting variables. Note that for the line plots throughout this report, a solid line will indicate a method that does not involve performing selection of covariates (i.e., using no or all covariates). A dashed line will indicate a method that does involve performing a non-trivial selection of covariates. A dotted black line will indicate the expected value (if applicable). For example, there will be a dotted line at $\alpha = 0.05$, the signifance level considered here and hence, the expected Type I error rate.

## Type I Error

  In the case of a zero $X$ effect, we set the population parameter for $X$ to be zero (i.e., $b_x = 0$), so that any significant result found is a Type I error. The first comparison will look at selection method overall, aggregated across all research settings. In Figure [@typeI-bar], the proportion of significant effects -- the Type I error -- is calculated and displayed. 

{{< embed notebooks/mak_figures.qmd#fig-typeI-bar >}}

Previous findings are replicated that using p-hacking for selecting covariates leads to a highly inflated Type I error rate (0.198). The p-hacked model consistently shows high Type I error, as is evident in the remaining figures in this section. Most methods are at the expected 0.050 mark, while the partial correlation approach shows slight inflation (0.052), with both LASSO and full linear model showing further inflation (0.057 and 0.060, respectively). These eight methods (excluding p-hacking) can be considered statistically valid as they show little to no inflation of Type I error rates.  

*supplemental material*

### By Research Settings

This section will consider the Type I error rates across the established values of the research context variables.

Figure [@fig-typeI-nobs] displays the change in Type I error as the number of observations in a sample increases for all nine methods. 

{{< embed notebooks/mak_figures.qmd#fig-typeI-nobs >}}

At the smallest sample size ($n=50$), the discrepancy between methods is greatest, with partial correlation, LASSO, and full linear model deviating from the expected value of 0.05. However, as sample size increases, all methods become comparable, especially with $n=300$ or larger.  

Figure [@fig-typeI-ncovs] displays the change in Type I error as the number of covariares increases for all nine methods. Recall that the number of covariates refers to the number of available covariates, not necessarily the number included in the final model.

{{< embed notebooks/mak_figures.qmd#fig-typeI-ncovs >}}

There is a slight increase in Type I error for LASSO and full linear model as the number of covariates increases, while the other methods stay at or around 0.05.

Figure [@fig-typeI-pgoodcovs] displays the change in Type I error as the proportion of good covariares increases for all nine methods.

{{< embed notebooks/mak_figures.qmd#fig-typeI-pgoodcovs >}}

Most of the methods remain stagnant in Type I error as the proportions increase, except the error of LASSO decreases slightly and that of full linear model increases.

Figure [@fig-typeI-rycov] shows the change in Type I error as the correlation between $Y$ and the good covariates increases for all nine methods. The correlation among the good covariates did not vary, so only the $Y$-covariate correlation will be compared.

{{< embed notebooks/mak_figures.qmd#fig-typeI-rycov >}}

All of the valid methods did not see a great change in Type I error as the correlation increased. 

## Parameter Estimates

*supplemental material*

As mentioned, this section considers a population parameter of $X$ set to zero. Figure [@fig-distribution-bx-0] shows the sampling distribution for the parameter estimate of $X$ for all nine methods.

{{< embed notebooks/mak_figures.qmd#fig-distribution-bx-0 >}}

This distribution highlights another negative consequence of p-hacking. In addition to inflation of Type I error rates, it biases the parameter estimates. While it is centered around zero, its bimodal distribution emphasizes how it biases the estimates. The remaining distributions are centered around zero. The model fit with no covariates has the widest distribution, indicating greater variability in its estimate for the $X$ effect.

## Type II Error

In the case of a nonzero $X$ effect, we tested two values for the population parameter for $X$, 0.3 and 0.5 (i.e., $b_x=0.3, b_x=0.5$), so that any non-significant result found is a Type II error. There is no benchmark of expected Type II error as there was for Type I, so the stronger methods will be those with lower Type II error (implying greater statistical power). As the p-hacked method was established as a method that is not statistically valid, it will not be considered in comparisons of Type II error.

The first comparison will look at selection method overall, aggregated across all research settings, for both effect sizes. In Figure [@typeII-bar-03] and Figure [@typeII-bar-05], the proportion of non-significant effects -- the Type II error -- is calculated and displayed. 

{{< embed notebooks/mak_figures.qmd#fig-typeII-bar-03 >}}

{{< embed notebooks/mak_figures.qmd#fig-typeII-bar-05 >}}

For both effect sizes, similar trends are shown. Fitting a model with no covariates results in the highest Type II error. When further examining the error rates within research settings, the no covariates approach will continue to yield the highest Type II error. There is a large reduction in error when all covariates are included in the model instead of no covariates. Additionally, performing selection of these covariates further reduces Type II error from simply including all covariates.    

### By Research Settings

Figure [@fig-typeII-nobs-03] and Figure [@fig-typeII-nobs-05] display the change in Type II error as the number of observations in a sample increases for all eight methods. 

{{< embed notebooks/mak_figures.qmd#fig-typeII-nobs-03 >}}

{{< embed notebooks/mak_figures.qmd#fig-typeII-nobs-05 >}}

At the smallest sample size, the methods differ in Type II error, with LASSO and partial correlation approaches yielding the lowest in both effect size cases. As sample size increases, the seven methods (excluding the no covariates method) tend to become indistinguishable. 

Figure [@fig-typeII-ncovs-03] and Figure [@fig-typeII-ncovs-05] display the change in Type II error as the number of covariates increases for all eight methods. 

{{< embed notebooks/mak_figures.qmd#fig-typeII-ncovs-03 >}}

{{< embed notebooks/mak_figures.qmd#fig-typeII-ncovs-05 >}}

For the smallest number of covariates, the methods are comparable in Type II error, but for larger numbers of covariates, there is a larger gap in performance. As the number of covariates increases, LASSO begins to have the lowest Type II error, followed by the partial correlation and bivariate correlation approaches. Additionally, the method of including all covariates becomes out-performed by the selection methods.  

Figure [@fig-typeII-pgoodcovs-03] and Figure [@fig-typeII-pgoodcovs-05] display the change in Type II error as the proportion of good covariates increases for all eight methods. 

{{< embed notebooks/mak_figures.qmd#fig-typeII-pgoodcovs-03 >}}

{{< embed notebooks/mak_figures.qmd#fig-typeII-pgoodcovs-05 >}}

For higher proportions of good covariates, LASSO, partial correlation, and bivariate correlation have the lowest Type II error.

Figure [@fig-typeII-rycov-03] and Figure [@fig-typeII-rycov-05] display the change in Type II error as the correlation between $Y$ and the good covariates increases for all eight methods. 

{{< embed notebooks/mak_figures.qmd#fig-typeII-rycov-03 >}}

{{< embed notebooks/mak_figures.qmd#fig-typeII-rycov-05 >}}

All methods (excluding the no covariates approach) show similar decreasing trends in Type II error as the correlation between $Y$ and the good covariates increases. The differences between these methods are minimal. 

## Parameter Estimates

As mentioned, this section considers two population parameters of $X$ set to 0.3 and 0.5 Figure [@fig-distribution-bx-03] and Figure [@fig-distribution-bx-05] show the sampling distributions for the parameter estimate of $X$ for all eight methods.

{{< embed notebooks/mak_figures.qmd#fig-distribution-bx-03 >}}

{{< embed notebooks/mak_figures.qmd#fig-distribution-bx-05 >}}

Both distributions show parameter estimates centered around the population values. In both effect size cases, the method including no covariates has a wider distribution, and therefore, more variability in its parameter estimates. 

# Discussion

This paper seeks to empirically compare methods for covariate selection in linear models. R scripts were used to generate data, fit linear models, and extract and visualize model results. The data generation process was based on full crossings of levels of variables which were chosen to represent common research settings in Psychology. Within each research setting, a unique dataset was simulated 40,000 times, with each dataset being used to fit the nine models and save the results. Simulations were ran using high-throughput computing.

The first step in evaluating the nine methods, was to establish which methods are statistically valid (i.e., have a Type I error rate of 0.05). We replicated previous findings that p-hacking is not a statistically valid method as it yielded inflated Type I error rates and also yielded biased parameter estimates. The remaining eight methods were found to be statistically valid, with LASSO and full linear model showing some inflation. 

With this established, the methods could be further compared by their Type II error rates. Lower Type II error can also be considered as higher statistical power. Including all covariates in a model shows a large reduction in Type II error compared to including no covariates in a model. Thus, researchers are encouraged to measure and use covariates. From there, performing a selection of covariates yields further reductions in Type II error compared to simply using all covariates. Overall, LASSO, partial correlation, and bivariate correlation resulted in the lowest Type II errors. However, there are more factors to take into consideration.

Depending on the research setting, researchers may prefer one method over another. As sample size increases (especially past $n=200$), the performance of methods tends to become indistinguishable. For the largest number of covariates tested (20), LASSO had the lowest Type II error, but for smaller numbers, it is comparable to partial correlation. LASSO showed more inflation of Type I error than the partial correlation approach which in turn showed more inflation than the bivariate correlation approach. Among these three, LASSO is the most computationally expensive and will come with a steep learning curve for new users. The bivariate correlation approach showed no inflation of Type I error, but underestimated the parameter estimates for the nonzero $X$ effects. The partial correlation approach did have slight inflation of Type I error, but correctly estimated the parameter estimates for the nonzero effects. The partial correlation approach also had lower Type II error than the bivariate correlation approach, overall and within different research contexts. With this information, researchers should consider what to prioritize depending on their goals.

# References

